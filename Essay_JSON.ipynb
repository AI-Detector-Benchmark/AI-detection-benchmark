{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzqxZvdJqoauCOs+cc3dcR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/humlaye/AI-detection-benchmark/blob/main/Essay_JSON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu kod csv dosyasında bulunan metinleri ID'leri ile tek tek bir JSON yapısına getirmektedir."
      ],
      "metadata": {
        "id": "NAzA6JU0WFny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"Google Drive bağlanıyor...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Drive başarıyla bağlandı.\")"
      ],
      "metadata": {
        "id": "A0tQcz5xuC-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dosya yolları belirtme yeri\n",
        "DRIVE_ROOT_PATH = '/content/drive/MyDrive/Fırat Projeler/Detecting AI Influence in Student Writing: Toward Reliable and Interpretable Classifiers/feedback-prize-english-language-learning'\n",
        "TRAIN_CSV_PATH = os.path.join(DRIVE_ROOT_PATH, 'train.csv')\n",
        "TEXT_FOLDER = os.path.join(DRIVE_ROOT_PATH, 'train')\n",
        "OUTPUT_FILE_PATH = os.path.join(DRIVE_ROOT_PATH, 'ell_essay_families_structure.jsonl')\n",
        "\n",
        "if not os.path.exists(TRAIN_CSV_PATH):\n",
        "    print(f\"\\nHATA: '{TRAIN_CSV_PATH}' yolu bulunamadı. Lütfen DRIVE_ROOT_PATH'i kontrol edin.\")\n",
        "else:\n",
        "\n",
        "\n",
        "    # train.csv dosyasını okuma (Metin ID'leri için)\n",
        "    print(f\"\\n'{TRAIN_CSV_PATH}' dosyası okunuyor...\")\n",
        "    df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
        "\n",
        "    # Sadece metin ID'leri ve skor\n",
        "    unique_essays = df_train.drop_duplicates(subset=['text_id']).set_index('text_id')\n",
        "\n",
        "    # JSON yapısını tutacak ana liste\n",
        "    text_family_data = []\n",
        "\n",
        "    print(f\"\\n{len(unique_essays)} adet deneme metni için JSON yapısı oluşturuluyor.\")\n",
        "\n",
        "    # Her bir deneme metnini JSON yapısına dönüştürme\n",
        "    for text_id in unique_essays.index:\n",
        "        essay_file_name = f\"{text_id}.txt\"\n",
        "        essay_file_path = os.path.join(TEXT_FOLDER, essay_file_name)\n",
        "\n",
        "        try:\n",
        "            with open(essay_file_path, 'r', encoding='utf-8') as f:\n",
        "                original_text = f.read()\n",
        "        except FileNotFoundError:\n",
        "            # Hata oluşursa atla\n",
        "            # print(f\"Hata: {essay_file_name} bulunamadı, atlanıyor.\")\n",
        "            continue\n",
        "\n",
        "        scores = unique_essays.loc[text_id, ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']].to_dict()\n",
        "\n",
        "        # JSON yapısı\n",
        "        family_object = {\n",
        "            \"family_id\": text_id,\n",
        "            \"source\": {\n",
        "                \"type\": \"student_essay_ell\",\n",
        "                \"original_scores\": scores,\n",
        "                \"path\": essay_file_name\n",
        "            },\n",
        "            \"versions\": [ # İleride buraya AI versiyonların eklenecek.\n",
        "                {\n",
        "                    \"type\": \"original\",\n",
        "                    \"text\": original_text,\n",
        "                    \"length_chars\": len(original_text),\n",
        "\n",
        "                }\n",
        "            ],\n",
        "            \"detection_results\": {},\n",
        "            \"metadata\": {\n",
        "                \"creation_date\": pd.Timestamp.now().isoformat(),\n",
        "                \"notes\": \"Original text extracted from Feedback Prize ELL dataset.\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "        text_family_data.append(family_object)"
      ],
      "metadata": {
        "id": "lZOT68-BuDFG",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#kaydetme\n",
        "print(f\"\\nOluşturulan veri {OUTPUT_FILE_PATH} dosyasına kaydediliyor.\")\n",
        "\n",
        "    # JSON Lines formatında kaydetme\n",
        "    with open(OUTPUT_FILE_PATH, 'w', encoding='utf-8') as f:\n",
        "        for item in text_family_data:\n",
        "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
        "\n",
        "    print(\"İşlem Tamamlandı\")\n",
        "    print(f\"Toplam {len(text_family_data)} adet metin ailesi yapısı oluşturuldu.\")\n",
        "    print(f\"JSONL Dosyanız Drive'da kaydedildi: {OUTPUT_FILE_PATH}\")\n"
      ],
      "metadata": {
        "id": "9RruMvAQuDHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# var olan bir kısmı kontrol etme\n",
        "print(\"\\n--- Örnek Yapı (İlk Metin) ---\")\n",
        "print(json.dumps(text_family_data[0], indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "id": "zaFDhFL4uDKO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}